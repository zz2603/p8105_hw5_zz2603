---
title: "p8105_hw5_zz2603"
author: "Ziyi Zhao"
date: "11/5/2019"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(viridis)

```


# Problem 1
```{r}
set.seed(10)

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species)) %>% 
  janitor::clean_names()

output <- vector("list",length = 5)

missiris <- function(x) {
    if (is.numeric(x)) {
      x[is.na(x)] = mean(x,na.rm = TRUE)
      } else if (is.character(x)) {
      x[is.na(x)] <- "virginica"
      }
  x
}

num_col = dim(iris_with_missing)[2]
for (i in 1:num_col) {
  output[[i]] = missiris(iris_with_missing[[i]])
}

output = map(iris_with_missing,missiris)

```

# Problem 2
```{r}
name_study <- list.files(path = "./hw5_data/data")

study_df <- tibble(name_study) %>% t() %>% as_tibble()

dtlst = vector("list",length = 20)
longdata <- function(x) {
  a = read_csv(paste0("./hw5_data/data/",x[[i]])) %>%
  t() %>% as_tibble()
  a
}

for (i in 1:20) {
  dtlst[[i]] = longdata(study_df)
}

dflst = vector("list",length = 20)
dflst[[1]] <- dtlst[[1]]
for (i in 2:20) {
  dflst[[i]] <- bind_cols(dflst[[i-1]],dtlst[i])  
}

finaldf <- dflst[[20]]
colnames(finaldf) <- substr(study_df[1,],1,6)
finaldf <- bind_cols(finaldf,tibble(Week = c(1:8)))

tidydf <- finaldf %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    con_01:exp_10,
    names_to = "Arm_ID",
    values_to = "Weekly_data"
  )

tidydf %>% 
  mutate(arm = substr(Arm_ID,1,3)) %>% 
  ggplot(aes(x=week,y=Weekly_data))+
  geom_line(aes(group=Arm_ID,color=arm))+
  scale_color_viridis(name="Arm",discrete = TRUE)+
  theme_classic()+
  labs(
    x="Time (Weeks)",
    y="Weekly Data",
    title = "Longitudinal Study"
  )+
  theme(
    plot.title = element_text(face = "bold")
  )

```

From the plot, we can find there is a general increasing trend in experiment group as the time increase. The data of two groups between week 2 are largely overlapped, but then the values of experiment group began to increase slightly as time p increase. The general trend among control group tends to be flat. Until week 6, most subjects in experiment group have greater values than values in control groups.

# Problem 3
```{r, message=FALSE}
set.seed(1)

output = vector("list", 10000)

sim_regression = function(n=30,beta0=2,beta1) {
  sim_data = tibble(
    x = rnorm(n),
    y = beta0 + beta1 * x + rnorm(n,0,sqrt(50)) 
  )
  
  ls_fit = lm(y ~ x, data = sim_data)
  
  fits = summary(ls_fit)[[4]] %>% broom::tidy() %>% janitor::clean_names()
  
  fits
}

## when beta1 = 0
for (i in 1:10000) {
  output[[i]] = sim_regression(beta1 = 0)
}

sim_results = bind_rows(output) %>% 
  filter(rownames=="x") %>% 
  select(estimate,pr_t)

## when beta1 is equal to 1 to 6
beta1_list = list("beta1_1" = 1, 
                  "beta1_2" = 2,
                  "beta1_3" = 3,
                  "beta1_4" = 4,
                  "beta1_5" = 5,
                  "beta1_6" = 6)

output1 = vector("list",length=6)
for (i in 1:6) {
  output1[[i]] = rerun(10000, sim_regression(beta1=beta1_list[[i]])) %>% 
    bind_rows() %>% filter(rownames=="x") %>% 
    mutate(coeff = rownames,
           coeff = recode(coeff,"x" = paste0("beta1_",i))) %>% 
    select(coeff, pr_t)
}

sim1to6_result = bind_rows(output1) %>% 
  group_by(coeff) %>% 
  mutate(if_reject = case_when(
    pr_t > 0.05 ~ "fail to reject",
    pr_t <= 0.05 ~ "reject")
  ) %>% group_by(coeff,if_reject) %>% 
  summarize(n=n(),prop = n / 10000) %>% 
  filter(if_reject=="reject")

sim1to6_result %>% ggplot(aes(x=coeff,y=prop))+
  geom_bar(stat = "identity")+
  labs(x="True beta1 coefficient",
       y="Proportion of reject the null",
       title="Plot 1")+
  theme(plot.title = element_text(face = "bold"))+
  theme_classic()

```

There is an increasing trend between the proportion of times the null was rejected and the true value of beta1. There is a positive association between effect size and power.

```{r, message=FALSE}
output2 = vector("list",length=6)
for (i in 1:6) {
  output2[[i]] = rerun(10000, sim_regression(beta1=beta1_list[[i]])) %>% 
    bind_rows() %>% filter(rownames=="x") %>% 
    mutate(coeff = rownames,
           coeff = recode(coeff,"x" = paste0("beta1_",i))) %>% 
    select(coeff, estimate, pr_t)
}

bind_rows(output2) %>% 
  group_by(coeff) %>% 
  mutate(average_est = mean(estimate),
         if_reject = case_when(
    pr_t > 0.05 ~ "fail to reject",
    pr_t <= 0.05 ~ "reject")) %>% 
  filter(if_reject=="reject") %>% 
  mutate(av_rej_est = mean(estimate)) %>% 
  ggplot(aes(x=coeff,y=average_est))+
  geom_point()+
  geom_point(aes(x=coeff,y=av_rej_est,color="#CC0000"))+
  labs(
    x="True beta1 coefficient",
    y="average estimate of beta1",
    title="Plot 2 (overlayed with Average Estimates of Beta1 Among Rejected)"
  )+
  theme(plot.title = element_text(face = "bold"))+
  theme_classic()

```

We combine two plot with different values in y-axis together. The black dot stands for average beta1 estimates; the red dot stands for average beta1 estimate among dataset that reject null. As the true beta1 value increase, the difference between two average estimates of beta1 become smaller. Their values become closer to true beta1 values as the true beta1 value increase.

The average estimate of beta1 for which the null is rejected is approximately equal to the true value of beta1 as the beta1 get larger. We can borrow the result from last plot to explain this statement. As the effect size increases, the proportion of reject of the null increases, which mean the number of reject of the null approximate to the total number of the sample. As we calculate the mean, average beta1 estimate among reject datasets will approximate to the overall average beta1 estimate.   






